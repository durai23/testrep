{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Parallel Computing on the Local Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Computers have more than one core.* Wouldn't it be nice if we could use all the cores of our local machine from our [Jupyter][IP] notebook?\n",
    "\n",
    "[Jupyter][IP] makes this fairly easy. One of the tabs of your browser has the title \"Home\". If you switch to that tab, there's are several tabs within the web page. One of them is called \"IPython Clusters\". Click on \"IPython Clusters\", increase the number of engines in the \"default\" profile to 4, and click on Start. The status changes from stopped to running. After you did that come back to this tab.\n",
    "\n",
    "If the \"Clusters\" tab shows the message\n",
    "\n",
    "    Clusters tab is now provided by IPython parallel. See IPython parallel for installation details.\n",
    "    \n",
    "you need to quit your notebook server (make sure all your notebooks ar saved) and run the command \n",
    "\n",
    "    ipcluster nbextension enable\n",
    "    \n",
    "Now, when you start `jupyter notebook` you should see a field that lets you set the number of engines in the \"IPython Clusters\" tab.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[IP]: http://www.jupyter.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how we access the \"Cluster\". [IPython][IP] comes with a module [ipyparallel][IPp] that is used to access the engines, we just started. We first need to import Client.\n",
    "\n",
    "[IPp]: https://ipyparallel.readthedocs.io/en/latest/\n",
    "[IP]: http://www.ipython.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipyparallel import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc = Client(profile=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can list the ids of the engines attached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we create views of the engines by slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v01 = rc[0:2] # First two engines (0 and 1)\n",
    "v23 = rc[2:4] # Engines 2 and 3\n",
    "dview = rc[:] # All available engines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IPython provides a magic command ``%px`` to execute code in parallel. The target attribute is used to pick the engines, you want.\n",
    "\n",
    "Note, the commands prefixed with ``%px`` are *not* executed locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%px import numpy as np # import numpy on all engines as np\n",
    "import numpy as np # do it locally, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute a command both remotely and locally, you can use %%px and add `--local` as option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px --local \n",
    "np.__version__ # print the numpy version of the engines. Not how the output is prefixed. It can be accessed that way, too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The engines run ipython. Magic commands work, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%px %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%px import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is useful to be able to execute more than a single statement. The cell magic command %%px lets us do that. The option ``--target`` lets us choose which engines we want to use. Here we are using engines 0 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px --target 0:4\n",
    "a = np.random.random([10,10])\n",
    "plt.imshow(a, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the output can be graphical.\n",
    "\n",
    "Note that the imports, we performed with %px are not available in our notbook. We can fix that by using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with rc[:].sync_imports():\n",
    "    import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately mapping of namespaces does not work that way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the DirectView"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DirectView as the name implies lets you control each engine directly. You can push data to a particular (set of) engine(s). You can have the engine(s) execute a command and get results back. You decide if a command should be blocking or not.\n",
    "\n",
    "We can, for example, create two random 100 by 100 element matrices on each engine, multiply them, and then display them. On each engine the code would look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.random.random([100, 100])\n",
    "b = np.random.random([100, 100])\n",
    "c = a.dot(b)\n",
    "plt.imshow(c, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we learned before, we can use the ``%%px`` cell magic to execute this on all engines. Here we use the ``--target`` option to specify every second engine starting at 0. ``%px`` and ``%%px`` use the currently active view. By default that's the first view created. You can make a view active by calling ``view.activate(suffix)``. Use ``view.activate?`` to learn more about suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px --target 0::2\n",
    "a = np.random.random([100, 100])\n",
    "b = np.random.random([100, 100])\n",
    "c = a.dot(b)\n",
    "plt.imshow(c, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous calls were done blocking because the graphical output is blocking. You can ask the view if it is blocking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview.block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's leave out the imshow command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px \n",
    "a = np.random.random([100, 100])\n",
    "b = np.random.random([100, 100])\n",
    "c = a.dot(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Latency and Bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latency (the time until something happens) and bandwith (the amount of data we get through the network) are two important properties of your parallel system that define what is practical and what is not. We will use the ``%timeit`` magic to measure these properties. ``%timit`` and its sibbling ``%%timeit`` measure the run time of a statement (cell in the case of ``%%timeit``) by executing the statement multiple times (by default at least 3 times). For short running routines many loops of 3 executions are performed and the minimum time measured is then displayed. The number of loops and the number of executions can be adjusted. Take a look at the documentation. Give it a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first see how long it takes to send off a new task using ``execute`` and ``apply``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview.block = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first execute nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit dview.execute('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use a very minimal function. It just returns its argument. In this case the argument is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit dview.apply(lambda x : x, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll tell every view to perform a matrix-matrix multiplication (see [Matrix-Matrix Multiplication Using a DirectView](Matrix-Matrix-Multiplication-Using-a-DirectView) below for more about matrix multiplications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit dview.execute('c = a.dot(b)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll make the execution blocking. This means, we are measuring the time the function needs to return a result instead of just the time needed to launch the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview.block=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit dview.execute('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit dview.apply(lambda x : x, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit dview.execute('c = a.dot(b)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, we'll run it without a view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview.block=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start about 500 parallel tasks per second and finish about half as many. This gives an estimate of the granularity we need to use this model for efficient parallelization. Any task that takes less time than this will be dominated by the overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea about the bandwidth available let's push some arrays to the engines. We make this blocking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview.block=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.random.random(256*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit dview.push(dict(a=a))\n",
    "%timeit dview.push(dict(a=a[:128*1024]))\n",
    "%timeit dview.push(dict(a=a[:64*1024]))\n",
    "%timeit dview.push(dict(a=a[:32*1024]))\n",
    "%timeit dview.push(dict(a=a[:16*1024]))\n",
    "%timeit dview.push(dict(a=a[:8*1024]))\n",
    "%timeit dview.push(dict(a=a[:4*1024]))\n",
    "%timeit dview.push(dict(a=a[:2*1024]))\n",
    "%timeit dview.push(dict(a=a[:1024]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the bandwidth for the largest array and the smallest array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bwmax = 256 * 8 / 0.00123\n",
    "bwmin = 8 / 0.00459\n",
    "print(\"The bandwidth is between %.2f kB/s and %.2f kB/s.\" %( bwmin, bwmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-Matrix Multiplication Using a DirectView"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiplication is one of the favorites in HPC computing. It's computationally intensive---if done right---, easily parallelized with little communication, and the basis of many real world applications.\n",
    "\n",
    "Let's say, we have two matrices A and B, where\n",
    "\n",
    "$$ A = \\left ( \\begin{array}{cccc}\n",
    "                4 & 3 & 1 & 6 \\\\\n",
    "                1 & 2 & 0 & 3 \\\\\n",
    "                7 & 9 & 2 & 0 \\\\\n",
    "                2 & 2 & -1 & 4 \\\\\n",
    "               \\end{array}\n",
    "       \\right ) $$\n",
    "\n",
    "and \n",
    "\n",
    "$$ B = \\left ( \\begin{array}{cc}\n",
    "                \\frac{1}{12} & \\frac{1}{2} \\\\\n",
    "                \\frac{1}{9}  & \\frac{1}{4} \\\\\n",
    "                \\frac{1}{3}  &      1      \\\\\n",
    "                \\frac{1}{7}  & -\\frac{1}{3}\n",
    "                \\end{array}\n",
    "       \\right ). $$\n",
    "\n",
    "To calculate the element of $C = A B$ at row *i* and column *j*, we perform a dot (scalar) product of the ith row of A and the jth column of B:\n",
    "\n",
    "$$ C_{ij} = \\sum_k A_{i,k} B_{k, i} $$.\n",
    "\n",
    "For this to work, the number of columns in $A$ has to be equal to the number of rows in $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate two matrices of size n by n filled with random numbers using ``np.random.random``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 16\n",
    "A = np.random.random([n, n])\n",
    "B = np.random.random([n, n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy includes the dot product. For 2 dimensional arrays ``np.dot`` performs a matrix-matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "C = np.dot(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit np.dot(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different ways to parallelize a matrix-matrix multiplication. Each element of the matrix can be calculated independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit p = len(rc)\n",
    "C1h = [[rc[(i * n + j) % p].apply(np.dot, A[i,:], B[:,j]) for j in range(n)] for i in range(n)]\n",
    "dview.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This, however, produces $n^2$ short tasks and the overhead (latency) is just overwhelming.\n",
    "\n",
    "We want to calculate\n",
    "\n",
    "$$ C = \\left ( \\begin{array}{cccc}\n",
    "                4 & 3 & 1 & 6 \\\\\n",
    "                1 & 2 & 0 & 3 \\\\\n",
    "                7 & 9 & 2 & 0 \\\\\n",
    "                2 & 2 & -1 & 4 \\\\\n",
    "               \\end{array}\n",
    "       \\right ) \n",
    "              \\left ( \\begin{array}{cc}\n",
    "                \\frac{1}{12} & \\frac{1}{2} \\\\\n",
    "                \\frac{1}{9}  & \\frac{1}{4} \\\\\n",
    "                \\frac{1}{3}  &      1      \\\\\n",
    "                \\frac{1}{7}  & -\\frac{1}{3}\n",
    "                \\end{array}\n",
    "       \\right ). \n",
    "$$\n",
    "\n",
    "We can split the matrices into tiles. In the above example, we might use a 2 by 2 tile.\n",
    "\n",
    "$$ C = \\left ( \\begin{array} {cc}\n",
    "               a_{00} & a_{01} \\\\\n",
    "               a_{10} & a_{11}\n",
    "               \\end{array} \\right )\n",
    "       \\left ( \\begin{array} {c}\n",
    "               b_{00} \\\\\n",
    "               b_{10}\n",
    "               \\end{array} \\right )\n",
    "     = \\left ( \\begin{array} {c}\n",
    "               a_{00} b_{00} + a_{01} b_{10} \\\\\n",
    "               a_{10} b_{00} + a_{11} b_{10}\n",
    "               \\end{array} \\right )\n",
    "               ,\n",
    "$$\n",
    "\n",
    "where, for example, $a_{00}= \\left ( \\begin{array}{cc} 4 & 3 \\\\ 1 & 2 \\end{array} \\right )$. $a_{00}b_{00}$ is a matrix-matrix product and the addition of two matrices of the same shape is defined element by element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, we have two $n$ by $n$ matrices and we are going to split them in quadrants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 1024\n",
    "A = np.random.random([n, n])\n",
    "B = np.random.random([n, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit np.dot(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a00 = A[:n // 2, :n // 2]\n",
    "a01 = A[:n / 2, n // 2:]\n",
    "a10 = A[n // 2:, :n // 2]\n",
    "a11 = A[n // 2:, n // 2:]\n",
    "b00 = B[:n // 2, :n // 2]\n",
    "b01 = B[:n // 2, n // 2:]\n",
    "b10 = B[n // 2:, :n // 2]\n",
    "b11 = B[n // 2:, n // 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation of the partial results in Python looks very similar to the mathematical description above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c00 = np.dot(a00, b00) + np.dot(a01, b10)\n",
    "c01 = np.dot(a00, b01) + np.dot(a01, b11)\n",
    "c10 = np.dot(a10, b00) + np.dot(a11, b10)\n",
    "c11 = np.dot(a10, b01) + np.dot(a11, b11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "c00 = np.dot(a00, b00) + np.dot(a01, b10)\n",
    "c01 = np.dot(a00, b01) + np.dot(a01, b11)\n",
    "c10 = np.dot(a10, b00) + np.dot(a11, b10)\n",
    "c11 = np.dot(a10, b01) + np.dot(a11, b11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, this is slower than doing it directly...\n",
    "\n",
    "Next we create one view per engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d0 = rc[0]\n",
    "d1 = rc[1]\n",
    "d2 = rc[2]\n",
    "d3 = rc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c00h = d0.apply(lambda a, b, c, d : np.dot(a, b) + np.dot(c, d), a00, b00, a01, b10)\n",
    "c01h = d1.apply(lambda a, b, c, d : np.dot(a, b) + np.dot(c, d), a00, b01, a01, b11)\n",
    "c10h = d2.apply(lambda a, b, c, d : np.dot(a, b) + np.dot(c, d), a10, b00, a11, b10)\n",
    "c11h = d3.apply(lambda a, b, c, d : np.dot(a, b) + np.dot(c, d), a10, b01, a11, b11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c00h.wait()\n",
    "c01h.wait()\n",
    "c10h.wait()\n",
    "c11h.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c00 = c00h.get()\n",
    "c01 = c01h.get()\n",
    "c10 = c10h.get()\n",
    "c11 = c11h.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "c00h = d0.apply(lambda a, b, c, d : np.dot(a, b) + np.dot(c, d), a00, b00, a01, b10)\n",
    "c01h = d1.apply(lambda a, b, c, d : np.dot(a, b) + np.dot(c, d), a00, b01, a01, b11)\n",
    "c10h = d2.apply(lambda a, b, c, d : np.dot(a, b) + np.dot(c, d), a10, b00, a11, b10)\n",
    "c11h = d3.apply(lambda a, b, c, d : np.dot(a, b) + np.dot(c, d), a10, b01, a11, b11)\n",
    "c00h.wait()\n",
    "c01h.wait()\n",
    "c10h.wait()\n",
    "c11h.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing says, we have to stop at 4 tiles nor do we have to use square tiles. We could also recursively subdivide our tiles.\n",
    "\n",
    "The code is not any faster, because our implementation of numpy already blocks the matrices and uses all cores, but it shows the principle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
